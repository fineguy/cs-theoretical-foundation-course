\input{../base.tex}
\graphicspath{ {imgs/} }

\begin{document}

%==================================================
\mynonumbersection{ЛИНЕЙНОЕ ПРОГРАММИРОВАНИЕ}

%==================================================
\mysection{Линейное программирование}

%========================================
\mysubsection{Введение}

Линейное программирование начало получать большое внимание в 1940-х, когда люди были заинтересованы в минимизации стоимости различных систем при заданных различных ограничениях. Мы занимаемся ими сейчас, потому что мы можем решать их эффективно и очень большой класс задач может быть выражен в терминах ЛП. Линейное программирование оперирует переменными, линейными ограничения для этих переменных и линейной целевой функцией, которую необходимо максимизировать или минимизировать. Например:

\myequation{
x_1 \geq 0 \\
x_1 + x_2 \leq 2 \\
x_1 - x_2 \geq 1 \\
x_2 \geq 2 \\
\min \, 3x_1 + 2x_2 
}
\

Теперь рассмотрим пример задачи линейного программирования, называющейся ``задача о диете''. У нас есть $n$ продуктов и $m$ нутриентов, которые необходимы потреблять в достаточном количестве. Нам хочется потратить наименьшее возможное количество денег, питаясь с соблюдением этих требований. Пусть $a_{ij}$ обозначает количество нутриента $i$ в каждом продукте $j$; $b_i$ -- минимальное количество нутриента $i$, которое необходимо в здоровой диете; $c_j$ -- стоимость одной единицы продукта $j$; $x_j$ -- переменная, обозначающая количество продукта $j$, которое мы приобретём. Эти ограничения могут быть записаны в виде:

\myequation{
\sum_j a_{ij} x_j \geq b_j \\
x_j \geq 0
}
\

И целевая функция это минимизация общей стоимости:

\myequation{
\min \, \sum_j c_j x_j
}
\

Чтобы переписать задачу в матричной форме, обозначим $A$ как матрицу размера $m \times n$, где $A_{ij} = a_{ij}$; $B$ -- матрица размера $m \times 1$, где $B_i = b_i$; $x$-- столбец переменных размера $n \times 1$; $c$ -- столбец размера $n \times 1$, где $c_i = c_i$. Тогда мы можем записать ограничения как:

\myequation{
Ax \geq b \\
x \geq 0
}
\

И целевую функцию как:

\myequation{
\min \, c^T x
}
\

В общем виде задачу ЛП можно записать в :

\mydefinition{
\textbf{нормальной} форме

\myequation{
\min \, c^T x \\
A x \geq b \\
}
}
\

\mydefinition{
и в \textbf{канонической} форме:

\myequation{
\min \, c^T x \\
A x = b \\
x \geq 0
}
}
\

\mytheorem{
Нормальная и канонические формы эквивалентны
}
\

\myproof{
Для перехода из нормальной формы к канонической нам нужно сделать две вещи. Во-первых, мы можем ввести дополнительные переменные для каждого ограничения вида неравенство $a_i x \geq b_i$, чтобы получить ограничение вида равенство $a_i x - s_i = b_i$. Во-вторых, мы можем заменить каждую переменную $x_i$ на $x_i^+ - x_i^-$, где $x_i^+, x_i^- \geq 0$. Очевидно, что полученная задача имеет те же решения, что и исходная.

Для перехода из канонической формы к нормальной нам нужно заменить каждое ограничение вида равенство $a_i x = b_i$ на два ограничения вида неравенство $a_i x \geq b_i$ и $a_i x \leq b_i$.
}
\

\mydefinition{
$x \in \mathbb{R}^n$ называется достижимым решением, если $x$ удовлетворяет всем ограничениям. Допустимое решение $x$ называется оптимальным, если оно минимизирует целевую функцию. 
}
\

%========================================
\mysubsection{Решение задачи ЛП}

Рассмотрим задачу ЛП в канонической форме:

\myequation{
\min \{ c^T x | A x = b , x \geq 0 \}
}
\

Без ограничения общности сделаем два допущения. Во-первых, мы положим, что уравнение $A x = b$ имеет решение, иначе исходная задача не имеет допустимых решений. Во-вторых, мы положим, что строки матрицы $A$ линейно независимы, иначе некоторые ограничения избыточно, и мы можем от них избавиться.

Заметим, что при этих допущениях ранг матрицы $A$ равен $m$ -- количество ограничений. Пусть $B \subseteq [n]$ -- подмножество индексов, определим матрицу $A_B$ как объединение $B$ колонок из матрицы $A$. Аналогично мы определим $x_B$ как колоночный вектор, состоящий из переменных $\{ x_i | i \in B \}$. Предположим, что есть некоторое подмножество $B$ из $m$ индексов такое, что колонки матрицы $A_B$ линейно независимы. Тогда матрица $A_B$ имеет полный ранг, а значит является обратимой матрицей, значит уравнение:

\myequation{
A_B x_B = b
}
\

имеет единственное решение:

\myequation{
x_B = A_B^{-1} b
}
\

Мы можем увеличить вектор $x_B$ до всех $n$ переменных, положив $x_i = 0$ для всех индексов $i \notin B$ -- этот вектор мы будем называть базисным решением. Заметим, что хотя базисное решение удовлетворяет ограничению $A x = b$, оно может не удовлетворять ограничению на неотрицательность. Мы будем называть базисное решение достижимым, если $x_B \geq 0$.

\myframe{
Каждое множество индексов $B$, задающее линейно независимый набор колонок и мощностью $m$, даёт ровно одно базисное решение и не более одного достижимого базисного решения.
}
\

\mytheorem{
Для каждой задачи ЛП в канонической форме справедливо одно из следующего: \\
\begin{enumerate}
  \item Задача ЛП неразрешима
  \item Задача ЛП имеет неограниченный экстремум
  \item Задача ЛП имеет достижимое базисное решение, которое является оптимальным
\end{enumerate}
}
\

\myproof{
Предположим, что наша задача ЛП разрешима и имеет ограниченный экстремум. Дополнительно предположим, что у нас есть $x^*$ -- достижимое решение. Теперь мы покажем, что существует достижимое базисное решение $x$ такое, что $c^T x \leq c^T x^*$. Таким образом мы получим, что для любого достижимого решения есть достижимое базисное решение с не большим значением целевой функции, из чего следует, что существует оптимальное достижимое базисное решение. 

Выберем достижимое решение $\tilde{x}$ среди всех таких, что $c^T x \leq c^T x^*$, и которое имеет наименьшее количество ненулевых координат. Пусть $P = \{ i | \tilde{x_i} > 0 \}$ -- множество координат, которые положительны. Заметим, что $\sum_{j \in P} A_j \tilde{x_j} = \sum_j A_j \tilde{x_j} = b$.

Возможны два случая. В первом случае колонки, соответствующие индексам из $P$ линейно зависимы. Так как $A$ имеет полный ранг, если нужно, мы можем добавить больше колонок из $[n] \backslash P$ к $P$, чтобы получить множество $B$ из $m$ индексов такое, что колонки матрицы $A_B$ также линейно независимы, тем самым $A_B$ является обратимой матрицей. Рассмотрим

\myequation{
A_B x_B = b
}
\

Существует уникальное решение $x_B$ для этого уравнения. Мы также знаем, что $\tilde{x_B}$ решение этого уравнения, значит оно должно быть уникальным решением. А раз $\tilde{x}$ достижимо, то оно является достижимым базисным решением соответствующим $B$.

Во втором случае предположим, что колонки матрицы $A_P$ линейно зависимы. Значит существуют коэффициенты $w_i$ не все одновременно равные нулю такие, что 

\myequation{
\sum_{j \in P} w_j A_j = A_P w_P = 0
}
\

Положив $w_j = 0$ для всех $j \notin P$ мы получим ненулевой вектор $w$ такой, что $A w = 0$. Таким образом, если мы рассмотрим вектор $y = \tilde{x} - \epsilon w$, то получим

\myequation{
A y = A (\tilde{x} - \epsilon w) = b - \epsilon 0 = b
}
\

Более того, так как вектор $w$ ненулевой только в координатах из $P$, и $x$ положительный в этих координатах, то для маленьких значений $\epsilon$ мы имеем, что $y = \tilde{x} - \epsilon w \geq 0$. Получается, что $y$ тоже достижимое решение при достаточно малых значениях эпсилон. 

Предположим, что нам повезло, и $c^T w = 0$. Тогда $c^T y = c^T (\tilde{x} - \epsilon w) = c^T \tilde{x}$. Мы можем положить, что $w$ имеет положительную координату, иначе можно заменить $w$ на $-w$. Тогда при увеличении $\epsilon$ мы уменьшаем некоторые положительные координаты в $y$ без изменения значения целевой функции. И в какой-то момент мы сделаем некоторые координаты нулевыми, вступая в противоречие с тем, что $\tilde{x}$ имеет наименьшее количество ненулевых координат среди всех $x$ таких, что $c^T x \leq c^T x^*$.

Теперь предположим, что $c^T x > 0$ (в противном случае мы можем заменить $w$ на $-w$). Снова, если существует одна положительная координата $w_j$ мы можем повторить предыдущий аргумент и получить противоречие. Остаётся случай, и когда все координаты $w$ отрицательные. Заметим, что тогда $y = \tilde{x} - \epsilon w$ неотрицательно, а значит достижимо для всех $\epsilon \geq 0$. Более того значение целевой функции $c^T y = c^T \tilde{x} - \epsilon(c^T w)$ стремится к $-\infty$ при $\epsilon \rightarrow \infty$. А это противоречит предположению, что задача ЛП имеет ограниченный экстремум.
}
\

%==================================================
\mysection{Применения ЛП}

%========================================
\mysubsection{Наилучшее разбиение двудольного графа}

Джордж Данциг изучал задачу наилучшего разбиения двудольного графа во время службы в армии. У него была группа людей, которым он хотел такое же количество задач. Он знал, что конкретный человек, выполняющий конкретную задачу, будет приносить армии определенную пользу. Его цель была в том, чтобы дать каждому человеку задачу таким образом, чтобы максимизировать общую пользу. Более формально, у нас есть двудольный граф $G = (U \cup V, E)$ с некоторым весами на рёбрах $w_{u, v} \forall (u, v) \in E$.

Первым желанием будет ввести переменные $x_{uv}$, которые равны 1, если мы даём человеку $u$ задачу $v$ и 0 в противном случае:

\myequation{
\max \, \sum_{(u, v) \in E} w_{uv} x_{uv} \\
0 \leq x_{uv} \leq 1 \\
x_{uv} \in \mathbb{Z} \\
\forall v \in V \sum_{u: (u, v) \in E} x_{uv} = 1 \\
\forall u \in U \sum_{v: (u, v) \in E} x_{uv} = 1
}
\

К сожалению нам мешает ограничение на целочисленность переменных. К счастью, мы можем воспользоваться релаксацией.

%==============================
\mysubsubsection{Релаксация}

Опустив ограничения на целочисленность переменных, мы получаем задачу ЛП. Заметим, что:

\begin{itemize}
  \item Новая задача ЛП всегда ограничена, так как ограничения задают $n$-мерный гиперкуб.
  \item Если полученная задача ЛП неразрешима, то исходная задача также неразрешима. Так как если множество допустимых решений задачи ЛП пусто, то оно не может содержать целочисленных решений.
  \item В общем случае оптимум исходной задачи $\leq$ оптимума задачи ЛП. 
\end{itemize}
\

\mytheorem{
Все экстремальные точки являются целочисленными.
}
\

\mytheorem{
Если полученная задача ЛП разрешима, то разрешима и исходная задача, причём их оптимумы совпадают.
}
\

\myproof{
Пусть $\tilde{x}$ достижимое и нецелочисленное решение. Тогда существует нецелочисленное ребро. Рассмотрим одну из его вершин -- она также должна иметь смежное нецелочисленное ребро в силу ограничений. Аналогично мы можем пойти вдоль этого другого ребра до противоположной вершины и найти ещё одно нецелочисленное ребро. Так как граф конечен и двудольный, то повторяя этот процесс мы в конце концов получим чётный цикл нецелочисленных рёбер $C$.

Пусть $\epsilon = \min ( \min_{(u,v) \in C} x_{uv}, \min_{(u,v) \in C} 1 - x_{uv}$. Другими словами $\epsilon$ это минимальное расстояние от одного из весов в этом цикле до целого числа. Пусть $x^+$ будет $\tilde{x}$ с добавленным $\epsilon$ к нечётным рёбрам и $-\epsilon$ к чётным. Пусть $x^-$ будет $\tilde{x}$ с добавленным $\epsilon$ к чётным рёбрам и $-\epsilon$ к нечётным. Теперь мы имеем, что $\tilde{x} = \frac{1}{2} x^+ + \frac{1}{2} x^-$.

Повторим этот процесс, пока все значения не будут целочисленными. Заметим, что значение целевой функции в точке $\tilde{x}$ равно среднему между значениями целевой функции в точках $x^+$ и $x^-$. А так как значения целевой функции в этих точках не больше, чем в оптимуме, то они должны быть равны оптимуму.
}
\

%==================================================
\mysection{Симплекс метод}

Симплекс метод позволяет переходить от одного достижимого базисного решения к другому более лучшему, улучшая значение целевой функции на каждом шаге. На входе имеем $A \in \mathbb{R}^{m \times n}, b, c \in \mathbb{R}$

\myequation{
\max \, c^T x \\
A x \leq b \\
x \geq 0
}
\

%========================================
\mysubsection{Алгоритм}

%==============================
\mysubsubsection{Шаг 1}

Введём дополнительные переменные $x_{n+1} \ldots x_{n+m}$ для каждого неравенства, сделав их равенствами. Эти выражения будут нашей ``расширенной'' таблицей, по которой мы максимизируем условие. Мы предполагаем, что у нас уже есть допустимое базисное решение в том смысле, что мы предполагаем, что если все небазисные переменные будут равны 0, то базисные переменные будут неотрицательными.

%==============================
\mysubsubsection{Шаг 2}

В выражении для максимизации выберем переменную с положительным коэффициентом. Она будет называться ведущей переменной. Если такой не существует, то мы просто обнуляем все базисные переменные.

%==============================
\mysubsubsection{Шаг 3}

Найдём равенство, которое наиболее сильно ограничивает ведущую переменную (устанавливает самую нижнюю верхнюю грань для неё). Решим это равенство относительно ведущей переменной и подставим полученное значение во все другие равенства, включая целевую функцию. Если нет ограничения на ведущую переменную, то и нет ограничения для целевой функции.

%==================================================
\mysection{Двойственная задача ЛП}

Для задачи ЛП:

\myequation{
P = \max (c^T x | A x \leq b, x \geq 0, x \in \mathbb{R}^n)
}
\

существует двойственная ей задача ЛП:

\myequation{
D = \min (b^T y | A^T y \geq c, x \geq 0, y \in \mathbb{R}^m)
}
\

%========================================
\mysubsection{Двойственная теорема ЛП}

\mytheorem{
\textbf{Слабая двойственная теорема ЛП.}
Пусть $P = \max (c^T x | A x \leq b, x \geq 0, x \in \mathbb{R}^n)$ и $D$ -- её двойственная задача $D = \min (b^T y | A^T y \geq c, x \geq 0, y \in \mathbb{R}^m)$. Если $x$ достижимое решение для $P$ и $y$ достижимое решение для $D$, то $c^T x \leq b^T y$
}
\

\myproof{
\myequation{
c^T x = x^T c \leq x^T (A^T y) = (A x)^T y \leq b^T y
}
}
\

Из этого мы можем заключить, что если $P$ неограничена, то $D$ неразрешима. Аналогично, если $D$ неограничена, то $P$ неразрешима. 

\mytheorem{
\textbf{Двойственная теорема ЛП.}
Если $P$ и $D$ двойственная пара задач ЛП, то имеет место один из случаев:
\begin{enumerate}
  \item Обе задачи неразрешимы.
  \item $P$ неограничена и $D$ неразрешима.
  \item $D$ неограничена и $P$ неразрешима.
  \item Обе задачи разрешимы, и существуют оптимальные решения $x, y$ для $P$ и $D$ такие, что $c^T x = b^T y$.
\end{enumerate}
}
\

\end{document}

